{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os, torch, pickle\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['HF_HOME'] = str(pathlib.Path(\"~/scratch-llm/storage/cache/huggingface/\").expanduser().absolute()) # '/scratch-llm/storage/cache/'\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"] = \"~/scratch-llm/storage/models/\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from nebulagraph_lite import nebulagraph_let as ng_let\n",
    "from llama_index.graph_stores.nebula import NebulaPropertyGraphStore\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.base.llms.types import ChatMessage\n",
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "from llama_index.core.vector_stores.simple import SimpleVectorStoreData, SimpleVectorStore, VectorStoreQuery\n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from typing import List\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NebulaGraph conexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;47;75;124mMessage: Activating storaged...\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145mResult of `SHOW HOSTS`:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m    errors:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m        code: 0\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m    results:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m        spaceName: \u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m        data:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m            meta:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m                None, None, None, None, None, None, None\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m            row:\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m                127.0.0.1, 9779, ONLINE, 201, PrimeKG:100, PrimeKG_nebula:100, basketballplayer:1, PrimeKG:100, PrimeKG_nebula:100, basketballplayer:1, 3.8.0\u001b[0m\n",
      "\u001b[1;3;38;2;160;81;149m        columns:\u001b[0m\n",
      "\u001b[1;3;38;2;160;81;149m            Host, Port, Status, Leader count, Leader distribution, Partition distribution, Version\u001b[0m\n",
      "\u001b[1;3;38;2;212;80;135m        errors:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m            code: 0\u001b[0m\n",
      "\u001b[1;3;38;2;249;93;106m        latencyInUs: 1464\u001b[0m\n",
      "\u001b[1;3;38;2;168;255;159mInfo: loading basketballplayer dataset...\u001b[0m\n",
      "\u001b[1;3;38;2;210;161;255m\n",
      "  _   _      _           _        ____                 _     \n",
      " | \\ | | ___| |__  _   _| | __ _ / ___|_ __ __ _ _ __ | |__  \n",
      " |  \\| |/ _ | '_ \\| | | | |/ _` | |  _| '__/ _` | '_ \\| '_ \\ \n",
      " | |\\  |  __| |_) | |_| | | (_| | |_| | | | (_| | |_) | | | |\n",
      " |_| \\_|\\___|_.__/ \\__,_|_|\\__,_|\\____|_|  \\__,_| .__/|_| |_|\n",
      "                                                |_|          \n",
      "                                                lite version\n",
      "\u001b[0m\n",
      "\u001b[1;3;38;2;210;161;255m[ OK ] nebulagraph_lite started successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load NebulaGraph JupyterNotebook extension\n",
    "# !udocker pull vesoft/nebula-metad:v3\n",
    "# !udocker create --name=nebula-metad vesoft/nebula-metad:v3\n",
    "# !udocker setup --execmode=F1 nebula-metad\n",
    "# !udocker pull vesoft/nebula-graphd:v3\n",
    "# !udocker create --name=nebula-graphd vesoft/nebula-graphd:v3\n",
    "# !udocker setup --execmode=F1 nebula-graphd\n",
    "# !udocker pull vesoft/nebula-storaged:v3\n",
    "# !udocker create --name=nebula-storaged vesoft/nebula-storaged:v3\n",
    "# !udocker setup --execmode=F1 nebula-storaged\n",
    "\n",
    "n = ng_let(in_container=True)\n",
    "n.start() # Takes around 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;0;135;107m[OK] Connection Pool Created\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PrimeKG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PrimeKG_nebula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basketballplayer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name\n",
       "0           PrimeKG\n",
       "1    PrimeKG_nebula\n",
       "2  basketballplayer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext ngql\n",
    "%ngql --address 127.0.0.1 --port 9669 --user root --password nebula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleVectorStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual data into all_nodes_embeddded\n",
    "with open(os.path.expanduser('~/scratch-llm/storage/nodes/all_nodes_all-mpnet-base-v2.pkl'), 'rb') as f:\n",
    "    all_nodes_embedded: List[TextNode] = pickle.load(f)\n",
    "# Create dictionaries from the nodes\n",
    "embedding_dict = {node.id_: node.get_embedding() for node in all_nodes_embedded}\n",
    "text_id_to_ref_doc_id = {node.id_: node.ref_doc_id or \"None\" for node in all_nodes_embedded}\n",
    "metadata_dict = {node.id_: node.metadata for node in all_nodes_embedded}\n",
    "\n",
    "# Initialize the SimpleVectorStore with the dictionaries\n",
    "vector_store = SimpleVectorStore(\n",
    "    data = SimpleVectorStoreData(\n",
    "        embedding_dict=embedding_dict,\n",
    "        text_id_to_ref_doc_id=text_id_to_ref_doc_id,\n",
    "        metadata_dict=metadata_dict,\n",
    "    ),\n",
    "    stores_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NebulaPropertyGraphStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = NebulaPropertyGraphStore(\n",
    "    space = \"PrimeKG\",\n",
    "    username = \"root\",\n",
    "    password = \"nebula\",\n",
    "    url = \"nebula://localhost:9669\",\n",
    "    props_schema= \"\"\"`node_index` STRING, `node_type` STRING, `node_id` STRING, `node_name` STRING, \n",
    "        `node_source` STRING, `mondo_id` STRING, `mondo_name` STRING, `group_id_bert` STRING, \n",
    "        `group_name_bert` STRING, `orphanet_prevalence` STRING, `display_relation` STRING \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb2646e371b4dcf91c586c0fc258698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ebebec687545e4959476b2c92a6e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289b01ae3f66448a96712ec1276eef16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d369fb3bd140d4bc91a74a606f10c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cebee3e4cb48f292533b63b5058ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29b4939dc0a4d63b66f1d8387e83575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2525a31a8b420387f7daac7fca2667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc74e1e5b81403e8c5f9445a7114901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf87fb2871604cbc9b6fd57d30496fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fefbd8820044b8877424c4fc9c4605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1f6b74a9a04e6fb977a347153a566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da054ba19dd84d94bfa1901b31930cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", padding_side=\"left\", device_map=\"auto\")    \n",
    "if tokenizer.pad_token_id is None: #no <pad> token previously defined, only eos_token\n",
    "    tokenizer.pad_token = \"<|end_of_text|>\"\n",
    "    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    context_window=8192,\n",
    "    max_new_tokens=3048,\n",
    "    generate_kwargs={\n",
    "        \"temperature\": 0.10, \n",
    "        \"do_sample\": True,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"top_k\": 10, \n",
    "        \"top_p\": 0.9,\n",
    "        # \"repetition_penalty\": 0.9,  # Added to reduce repetition\n",
    "        # \"no_repeat_ngram_size\": 3,  # Prevents repetition of n-grams\n",
    "    },\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.float16,\n",
    "    },\n",
    "    tokenizer=tokenizer,\n",
    "    # device_map=\"auto\",  # Automatically offload layers to CPU if GPU memory is insufficient\n",
    "    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    stopping_ids=[tokenizer.eos_token_id],\n",
    "    tokenizer_kwargs={\"max_length\": None},\n",
    "    is_chat_model=True,\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 1024\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-mpnet-base-v2\") # BAAI/bge-small-en-v1.5 /  m3 / sentence-transformers/all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiseaseMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MetadataFilters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types import MetadataFilters, FilterOperator\n",
    "disease_dict = {\n",
    "    \"key\": \"node_type\",\n",
    "    \"value\": \"disease\",\n",
    "    \"operator\": FilterOperator.EQ\n",
    "}\n",
    "disease_filter = MetadataFilters(filters=[disease_dict])\n",
    "\n",
    "class DiseaseMode():\n",
    "    def __init__(self, vector_store: SimpleVectorStore, graph_store: NebulaPropertyGraphStore):\n",
    "        self.vector_store = vector_store\n",
    "        self.graph_store = graph_store\n",
    "\n",
    "    def retrieve(self, query: str):        \n",
    "        query_embedding = Settings.embed_model.get_text_embedding(query)\n",
    "        vector_results = self.vector_store.query(\n",
    "            VectorStoreQuery(\n",
    "                query_embedding=query_embedding, \n",
    "                similarity_top_k=1,\n",
    "                filters=disease_filter,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        top_node_id = vector_results.ids[0]\n",
    "        top_node_score = vector_results.similarities[0]\n",
    "        kg_node = self.graph_store.get(ids=[top_node_id])[0]\n",
    "                \n",
    "        results = [{ # Create results list with primary node\n",
    "            \"node_index\": kg_node.id_,\n",
    "            \"node_name\": kg_node.properties[\"node_name\"],\n",
    "            \"text\": getattr(kg_node, \"text\", \"\"),\n",
    "            \"score\": top_node_score\n",
    "        }]\n",
    "        \n",
    "        print(f\"Best node from vector query: Node ID: {kg_node.id_}, \"\n",
    "              f\"Score: {top_node_score:.4f}, Name: {kg_node.properties['node_name']}\")\n",
    "        \n",
    "        # Find related nodes through graph query\n",
    "        graph_nodes = self.graph_store.structured_query(\n",
    "            \"\"\"\n",
    "            MATCH (e:Node__) WHERE id(e) == $ids\n",
    "            MATCH p=(e)-[r:Relation__{label:\"disease-disease\"}]-(t) \n",
    "            UNWIND relationships(p) as rel\n",
    "            RETURN DISTINCT id(t), t.Props__.node_name, t.Chunk__.text\n",
    "            \"\"\", \n",
    "            param_map={\"ids\": top_node_id}\n",
    "        )\n",
    "        \n",
    "        # Calculate similarity for related nodes and add relevant ones to results\n",
    "        all_similarities = []\n",
    "        for node in graph_nodes:\n",
    "            node_text = node[\"t.Props__.node_name\"] + \": \" + node[\"t.Chunk__.text\"]\n",
    "            node_embedding = Settings.embed_model.get_text_embedding(node_text)\n",
    "                    \n",
    "            similarity = dot(query_embedding, node_embedding) / (norm(query_embedding) * norm(node_embedding))\n",
    "            all_similarities.append((node, similarity))\n",
    "            \n",
    "        if len(all_similarities) > 3:\n",
    "            sim = [s for _, s in all_similarities]\n",
    "            threshold = np.percentile(sim, 75) # keep top 25% of nodes\n",
    "        else:\n",
    "            threshold = 0.7\n",
    "        \n",
    "        for node, similarity in all_similarities:\n",
    "            if similarity > threshold: #and similarity >= 0.5:\n",
    "                results.append({\n",
    "                    \"node_index\": node[\"id(t)\"],\n",
    "                    \"node_name\": node[\"t.Props__.node_name\"],\n",
    "                    \"text\": node_text,\n",
    "                    \"score\": similarity\n",
    "                })\n",
    "        \n",
    "        results = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "        print(\"\\nBest related nodes from graph query:\")\n",
    "        for node in results:  # Skip primary node\n",
    "            print(f\"ID: {node['node_index']} | node name: {node['node_name']} | score: {node['score']:.4f}\")\n",
    "        \n",
    "        graph_phenotype = graph_store.structured_query(\n",
    "            \"\"\"\n",
    "            MATCH (e:Node__) WHERE id(e) == $ids\n",
    "            MATCH (e)-[r:Relation__{label:\"disease-phenotype-positive\"}]-(t) \n",
    "            RETURN DISTINCT id(t), t.Props__.node_name\n",
    "            \"\"\", \n",
    "            param_map={\"ids\": top_node_id}\n",
    "        )\n",
    "        # join the phenotype names without the \" '' \" characters\n",
    "        phenotypes = \", \".join(node[\"t.Props__.node_name\"].replace(\"'\", \"\") for node in graph_phenotype)\n",
    "\n",
    "        nodes_with_text = [node for node in results if node['text'].strip()]\n",
    "        context = [f\"'{node['node_name']}': {node['text']}\" for node in nodes_with_text] if nodes_with_text else None\n",
    "        phenotype_context = [f\"Is associated with the following phenotypes: {phenotypes}\\n\"] if phenotypes else None\n",
    "        \n",
    "        if results:\n",
    "            return (context, phenotype_context, top_node_id)\n",
    "        else:\n",
    "            return [f\"No graph relationships found for {results[0]['node_name']}\"] if results else [\"No results found\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_phenotype_template = \"\"\"    \n",
    "    Context information is below:\n",
    "    {text_chunks}\n",
    "\n",
    "    Phenotype context is below:\n",
    "    {phenotype_context}\n",
    "\n",
    "    You are a medical knowledge assistant specializing in rare diseases. Your task is to create a comprehensive list of symptoms for {query_str}.\n",
    "\n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    1. Use the information from the context and your own knowledge to provide a comprehensive answer\n",
    "    2. Return MAXIMUM the 16 most relevant symptoms, if there are more than 16 symptoms, return the most relevant ones\n",
    "    3. Use HPO medical terminology and avoid using including redundant symptoms\n",
    "    4. Return EXACTLY this JSON format (no variations):\n",
    "\n",
    "    Always format your response as a VALID JSON:\n",
    "    {\n",
    "        \"disease\": \"{query_str}\",\n",
    "        \"symptoms\": [\n",
    "            \"name symptom1 using HPO terminology\",\n",
    "            \"name symptom2 using HPO terminology\",\n",
    "            ... and so on\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    Do NOT use nested objects. Use exactly \"disease\" and \"symptoms\" as shown.\n",
    "\"\"\"\n",
    "\n",
    "no_rag_template = \"\"\"\n",
    "    You are a medical knowledge assistant specializing in rare diseases. Your task is to create a comprehensive list of symptoms for {query_str}.\n",
    "\n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    1. Use only your own knowledge to provide a comprehensive answer\n",
    "    2. Return MAXIMUM the 16 most relevant symptoms, if there are more than 16 symptoms, return the most relevant ones\n",
    "    3. Use only HPO medical terminology and avoid including redundant symptoms\n",
    "    4. Return EXACTLY this JSON format (no variations):\n",
    "\n",
    "    Always format your response as a VALID JSON:\n",
    "    {\n",
    "        \"disease\": \"{query_str}\",\n",
    "        \"symptoms\": [\n",
    "            \"name symptom1 using HPO terminology\",\n",
    "            \"name symptom2 using HPO terminology\",\n",
    "            \"name symptom3 using HPO terminology\",\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    Do NOT use nested objects. Use exactly \"disease\" and \"symptoms\" as shown.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAG === \n",
      "User query: Developmental and epileptic encephalopathy 4\n",
      "\n",
      "Best node from vector query: Node ID: 28987, Score: 0.7868, Name: developmental and epileptic encephalopathy, 85, with or without midline brain defects\n",
      "\n",
      "Best related nodes from graph query:\n",
      "ID: 28987 | node name: developmental and epileptic encephalopathy, 85, with or without midline brain defects | score: 0.7868\n",
      "ID: 28005 | node name: developmental and epileptic encephalopathy | score: 0.7537\n",
      "Context: [\"'developmental and epileptic encephalopathy': developmental and epileptic encephalopathy: Any earl\n",
      "Phenotypes: ['Is associated with the following phenotypes: Cleft palate, Retrognathia, Posteriorly rotated ears, Anteverted nares, Autistic behavior, Growth delay, Hypertonia, Delayed speech and language development, Stereotypy, Atrial septal defect, Talipes, Camptodactyly, Clinodactyly, Seizure, Hirsutism, Focal-onset seizure, Generalized hypotonia, Overfolded helix, Facial asymmetry, Choanal atresia, Widely spaced teeth, Hypoplasia of the corpus callosum, Bilateral tonic-clonic seizure, Broad hallux, Intrauterine growth retardation, Muscular hypotonia of the trunk, Congenital diaphragmatic hernia, EEG abnormality, Global developmental delay, Partial anomalous pulmonary venous return, Thin upper lip vermilion, Highly arched eyebrow, Hypsarrhythmia, Gastroesophageal reflux, Severe global developmental delay, Low anterior hairline, Round face, Smooth philtrum, Short philtrum, Triangular face, Narrow forehead, Narrow nose, Downslanted palpebral fissures, Upslanted palpebral fissure, Hypotelorism, Synophrys, Dental crowding, Poor eye contact, Tapered finger, Spastic tetraparesis, Absent speech, Hip dysplasia, X-linked dominant inheritance, Short foot, Semilobar holoprosencephaly, Downturned corners of mouth, Short nose, Congenital onset, Single median maxillary incisor, Contracture of the proximal interphalangeal joint of the 3rd finger, 1-2 toe syndactyly, Midface retrusion, Infantile spasms, Multifocal seizures, Delayed ability to walk, Seizure cluster, Small hand, Unilateral ptosis\\n']\n",
      "\n",
      "19 text chunks after repacking\n",
      "1 text chunks after repacking\n",
      "Top node ID: 28987\n",
      "\n",
      "RESPONSE OK: {\"disease\":\"Developmental and epileptic encephalopathy 4\",\"symptoms\":[\"Severe global developmental delay\",\"Global developmental delay\",\"Hypotonia\",\"Muscular hypotonia of the trunk\",\"Hypotonia\",\"Spastic tetraparesis\",\"Seizure\",\"Focal-onset seizure\",\"Bilateral tonic-clonic seizure\",\"Multifocal seizures\",\"Infantile spasms\",\"EEG abnormality\",\"Hypsarrhythmia\",\"Hypotelorism\",\"Synophrys\",\"Poor eye contact\",\"Absent speech\",\"Delayed speech and language development\"]}\n",
      "Symptoms retrieved: 18 for Developmental and epileptic encephalopathy 4\n",
      "\n",
      "\n",
      " === no RAG === \n",
      "User query: Developmental and epileptic encephalopathy 4\n",
      "\n",
      "\n",
      "RESPONSE OK: {\"disease\":\"Developmental and epileptic encephalopathy 4\",\"symptoms\":[\"encephalopathy\",\"epilepsy\",\"developmental delay\",\"seizures\",\"hypotonia\",\"hypomyelination\",\"microcephaly\",\"cerebral atrophy\",\"cerebral edema\",\"neuropathy\",\"autism\",\" intellectual disability\",\"speech impairment\",\"apnea\",\"hypersomnolence\",\"feeding difficulties\",\"failure to thrive\"]}\n",
      "Symptoms retrieved: 17 for Developmental and epileptic encephalopathy 4\n"
     ]
    }
   ],
   "source": [
    "user = \"autosomal dominant polycystic kidney disease\" # \"autosomal recessive polycystic kidney disease\"\n",
    "\n",
    "print(f\"\\n=== RAG === \\nUser query: {user}\\n\")\n",
    "context, phenotypes, top_node_id = DiseaseMode(vector_store, graph_store).retrieve(user)\n",
    "\n",
    "\n",
    "print(f\"\\nPhenotypes: {phenotypes}\")\n",
    "prompt_template = PromptTemplate(context_phenotype_template) \n",
    "summarizer = TreeSummarize(verbose=True, llm=llm, summary_template=prompt_template)\n",
    "\n",
    "response = summarizer.get_response(\n",
    "    query_str = user,\n",
    "    text_chunks = \"\\n\".join(context),\n",
    ")\n",
    "display(Markdown(response))\n",
    "\n",
    "\n",
    "print(f\"\\n\\n === no RAG === \\nUser query: {user}\\n\")\n",
    "# include a prompt template for the LLM chat \n",
    "template = PromptTemplate(no_rag_template)\n",
    "prompt = template.format(query_str=user)\n",
    "response = llm.chat([ChatMessage(role=\"user\", content=prompt)])\n",
    "\n",
    "# Extract the text content from the ChatResponse object\n",
    "response_text = response.message.content if hasattr(response, \"message\") else str(response)\n",
    "\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks with NebulaGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql CREATE SPACE IF NOT EXISTS PrimeKG(vid_type=FIXED_STRING(256))\n",
    "%ngql USE PrimeKG;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e.Props__.node_name</th>\n",
       "      <th>e.Chunk__.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wieacker-Wolff syndrome (spectrum)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  e.Props__.node_name e.Chunk__.text\n",
       "0  Wieacker-Wolff syndrome (spectrum)               "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "MATCH (e:Node__)\n",
    "WHERE id(e) == \"38849\"\n",
    "RETURN DISTINCT \n",
    "        e.Props__.node_name, \n",
    "        e.Chunk__.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e.Props__.node_name</th>\n",
       "      <th>e.Props__.node_type</th>\n",
       "      <th>e.Chunk__.text</th>\n",
       "      <th>t1.Props__.node_name</th>\n",
       "      <th>t1.Props__.node_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>familial focal alopecia</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Autosomal dominant inheritance</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>familial focal alopecia</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Patchy alopecia</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>myelolymphatic insufficiency</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Hyposegmentation of neutrophil nuclei</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>myelolymphatic insufficiency</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>X-linked recessive inheritance</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cerebellar, ocular, craniofacial, and genital syndrome</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Low-set ears</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12449</th>\n",
       "      <td>Wieacker-Wolff syndrome, female-restricted</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Inability to walk</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>Wieacker-Wolff syndrome, female-restricted</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Distal muscle weakness</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12451</th>\n",
       "      <td>Wieacker-Wolff syndrome, female-restricted</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Kyphosis</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>Wieacker-Wolff syndrome, female-restricted</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Flexion contracture</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>Wieacker-Wolff syndrome, female-restricted</td>\n",
       "      <td>disease</td>\n",
       "      <td></td>\n",
       "      <td>Generalized hypotonia</td>\n",
       "      <td>effect/phenotype</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12454 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          e.Props__.node_name e.Props__.node_type e.Chunk__.text                   t1.Props__.node_name t1.Props__.node_type\n",
       "0                                     familial focal alopecia             disease                        Autosomal dominant inheritance     effect/phenotype\n",
       "1                                     familial focal alopecia             disease                                       Patchy alopecia     effect/phenotype\n",
       "2                                myelolymphatic insufficiency             disease                 Hyposegmentation of neutrophil nuclei     effect/phenotype\n",
       "3                                myelolymphatic insufficiency             disease                        X-linked recessive inheritance     effect/phenotype\n",
       "4      cerebellar, ocular, craniofacial, and genital syndrome             disease                                          Low-set ears     effect/phenotype\n",
       "...                                                       ...                 ...            ...                                    ...                  ...\n",
       "12449              Wieacker-Wolff syndrome, female-restricted             disease                                     Inability to walk     effect/phenotype\n",
       "12450              Wieacker-Wolff syndrome, female-restricted             disease                                Distal muscle weakness     effect/phenotype\n",
       "12451              Wieacker-Wolff syndrome, female-restricted             disease                                              Kyphosis     effect/phenotype\n",
       "12452              Wieacker-Wolff syndrome, female-restricted             disease                                   Flexion contracture     effect/phenotype\n",
       "12453              Wieacker-Wolff syndrome, female-restricted             disease                                 Generalized hypotonia     effect/phenotype\n",
       "\n",
       "[12454 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "# find all disease nodes where e.Chunk__.text is empty\n",
    "MATCH (e:Node__)\n",
    "MATCH (e)-[r1:Relation__{label:\"disease-phenotype-positive\"}]-(t1) # {label:\"disease-phenotype-positive\"}\n",
    "WHERE e.Props__.node_type == \"disease\" AND e.Chunk__.text == \"\"\n",
    "RETURN DISTINCT \n",
    "    e.Props__.node_name,\n",
    "    e.Props__.node_type,\n",
    "    e.Chunk__.text,\n",
    "    t1.Props__.node_name,\n",
    "    t1.Props__.node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;47;75;124mudocker command: udocker /home/lasa14/.conda/envs/llm-rag/bin/udocker --allow-root ps | grep graphd | awk '{print $1}' | xargs -I {} udocker --allow-root rm -f {}\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145merror: Error: deleting directory:  /home/lasa14/.udocker/containers/d9a1b12a-62b5-3764-80e3-dd482130cc1d\n",
      "Error: deleting container\n",
      "\u001b[0m\n",
      "Retrying in 5 seconds... udocker command failed with return code 123\n",
      "\u001b[1;3;38;2;47;75;124mudocker command: udocker /home/lasa14/.conda/envs/llm-rag/bin/udocker --allow-root ps | grep graphd | awk '{print $1}' | xargs -I {} udocker --allow-root rm -f {}\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145merror: Error: deleting directory:  /home/lasa14/.udocker/containers/d9a1b12a-62b5-3764-80e3-dd482130cc1d\n",
      "Error: deleting container\n",
      "\u001b[0m\n",
      "Retrying in 15 seconds... udocker command failed with return code 123\n",
      "\u001b[1;3;38;2;47;75;124mudocker command: udocker /home/lasa14/.conda/envs/llm-rag/bin/udocker --allow-root ps | grep graphd | awk '{print $1}' | xargs -I {} udocker --allow-root rm -f {}\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145merror: Error: deleting directory:  /home/lasa14/.udocker/containers/d9a1b12a-62b5-3764-80e3-dd482130cc1d\n",
      "Error: deleting container\n",
      "\u001b[0m\n",
      "Process with PID 535765 has been terminated.\n",
      "Process with PID 534711 has been terminated.\n"
     ]
    }
   ],
   "source": [
    "n.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
