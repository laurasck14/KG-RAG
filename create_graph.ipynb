{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nebulagraph_lite import nebulagraph_let as ng_let\n",
    "import os, math, torch, re, pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from llama_index.core.schema import NodeRelationship, TextNode, RelatedNodeInfo\n",
    "from llama_index.graph_stores.nebula import NebulaPropertyGraphStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from typing import Sequence, List\n",
    "from llama_index.core.schema import BaseNode, MetadataMode\n",
    "from llama_index.core.embeddings.utils import resolve_embed_model\n",
    "from llama_index.core.settings import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;47;75;124mMessage: Activating storaged...\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145mResult of `SHOW HOSTS`:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m    errors:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m        code: 0\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m    results:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m        spaceName: \u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m        data:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m            meta:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m                None, None, None, None, None, None, None\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m            row:\u001b[0m\n",
      "\u001b[1;3;38;2;102;81;145m                127.0.0.1, 9779, ONLINE, 201, PrimeKG:100, PrimeKG_nebula:100, basketballplayer:1, PrimeKG:100, PrimeKG_nebula:100, basketballplayer:1, 3.8.0\u001b[0m\n",
      "\u001b[1;3;38;2;160;81;149m        columns:\u001b[0m\n",
      "\u001b[1;3;38;2;160;81;149m            Host, Port, Status, Leader count, Leader distribution, Partition distribution, Version\u001b[0m\n",
      "\u001b[1;3;38;2;212;80;135m        errors:\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m            code: 0\u001b[0m\n",
      "\u001b[1;3;38;2;249;93;106m        latencyInUs: 958\u001b[0m\n",
      "\u001b[1;3;38;2;168;255;159mInfo: loading basketballplayer dataset...\u001b[0m\n",
      "\u001b[1;3;38;2;47;75;124m\n",
      "  _   _      _           _        ____                 _     \n",
      " | \\ | | ___| |__  _   _| | __ _ / ___|_ __ __ _ _ __ | |__  \n",
      " |  \\| |/ _ | '_ \\| | | | |/ _` | |  _| '__/ _` | '_ \\| '_ \\ \n",
      " | |\\  |  __| |_) | |_| | | (_| | |_| | | | (_| | |_) | | | |\n",
      " |_| \\_|\\___|_.__/ \\__,_|_|\\__,_|\\____|_|  \\__,_| .__/|_| |_|\n",
      "                                                |_|          \n",
      "                                                lite version\n",
      "\u001b[0m\n",
      "\u001b[1;3;38;2;210;161;255m[ OK ] nebulagraph_lite started successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load NebulaGraph JupyterNotebook extension\n",
    "# !udocker pull vesoft/nebula-metad:v3\n",
    "# !udocker create --name=nebula-metad vesoft/nebula-metad:v3\n",
    "# !udocker setup --execmode=F1 nebula-metad\n",
    "# !udocker pull vesoft/nebula-graphd:v3\n",
    "# !udocker create --name=nebula-graphd vesoft/nebula-graphd:v3\n",
    "# !udocker setup --execmode=F1 nebula-graphd\n",
    "# !udocker pull vesoft/nebula-storaged:v3\n",
    "# !udocker create --name=nebula-storaged vesoft/nebula-storaged:v3\n",
    "# !udocker setup --execmode=F1 nebula-storaged\n",
    "\n",
    "n = ng_let(in_container=True)\n",
    "n.start() # This takes around 5 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;0;135;107m[OK] Connection Pool Created\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PrimeKG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PrimeKG_nebula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basketballplayer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name\n",
       "0           PrimeKG\n",
       "1    PrimeKG_nebula\n",
       "2  basketballplayer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext ngql\n",
    "%ngql --address 127.0.0.1 --port 9669 --user root --password nebula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the graph from NebulaGraph directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql CREATE SPACE IF NOT EXISTS PrimeKG_nebula(vid_type=FIXED_STRING(256));\n",
    "%ngql USE PrimeKG_nebula;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primekg = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/raw_data/kg.csv\", low_memory=False)\n",
    "nodes = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/raw_data/nodes.csv\",\n",
    "    low_memory=False,\n",
    "    sep=',',\n",
    "    quotechar='\"',  \n",
    "    escapechar='\\\\', \n",
    ")\n",
    "\n",
    "edges = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/raw_data/edges.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes['node_type'].unique()) #types of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data for each 'node_type' in a separate file\n",
    "for node_type in nodes['node_type'].unique():\n",
    "    sanitized_node_type = node_type.replace('/', '_')\n",
    "    output_path = os.path.join('~/scratch-llm/data/PrimeKG_data/sub_data/', 'node_'+ sanitized_node_type + '.csv')\n",
    "    nodes[nodes['node_type'] == node_type].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Tags (node_type) for each node in the PrimeKG\n",
    "%ngql CREATE TAG IF NOT EXISTS anatomy(node_name string, node_source string, node_id string);\n",
    "%ngql CREATE TAG IF NOT EXISTS gene_protein(node_name string, node_source string, node_id string);\n",
    "%ngql CREATE TAG IF NOT EXISTS drug(node_name string, node_source string, node_id string, description string, half_life string, indication string, mechanism_of_action string, protein_binding string, pharmacodynamics string, state string, atc_1 string, atc_2 string, atc_3 string, atc_4 string, category string, group string, pathway string, molecular_weight string, tpsa string, clogp string);\n",
    "%ngql CREATE TAG IF NOT EXISTS disease(node_name string, node_source string, mondo_id int, mondo_name string, group_id_bert string, group_name_bert string, mondo_definition string, umls_description string, orphanet_definition string, orphanet_prevalence string, orphanet_epidemiology string, orphanet_clinical_description string, orphanet_management_and_treatment string, mayo_symptoms string, mayo_causes string, mayo_risk_factors string, mayo_complications string, mayo_prevention string, mayo_see_doc string);\n",
    "%ngql CREATE TAG IF NOT EXISTS pathway(node_name string, node_source string, node_id string);\n",
    "%ngql CREATE TAG IF NOT EXISTS biological_process(node_name string, node_source string, node_id string);\n",
    "%ngql CREATE TAG IF NOT EXISTS effect_phenotype(node_name string, node_source string, node_id string);\n",
    "%ngql CREATE TAG IF NOT EXISTS molecular_function(node_name string, node_source string, node_id string);\n",
    "%ngql CREATE TAG IF NOT EXISTS cellular_component(node_name string, node_source string, node_id string);\n",
    "%ngql CREATE TAG IF NOT EXISTS exposure(node_name string, node_source string, node_id string);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each node source data into the corresponding Tag (working fine)\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_gene_protein.csv --tag gene_protein --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_biological_process.csv --tag biological_process --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_effect_phenotype.csv --tag effect_phenotype --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_molecular_function.csv --tag molecular_function --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_cellular_component.csv --tag cellular_component --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_pathway.csv --tag pathway --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_exposure.csv --tag exposure --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_anatomy.csv --tag anatomy --header --space PrimeKG --vid 0 --props 2:node_id,3:node_name,4:node_source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra information for nodes 'drug' and 'disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disease and drug feature files are available as .tab format so they need to be converted to .csv\n",
    "# many formatting issues on both files that had to be correcteed manually before merging with the 'node_' dataset\n",
    "disease_tab = \"~/scratch-llm/data/PrimeKG_data/raw_data/disease_features.tab\"\n",
    "drug_tab = \"~/scratch-llm/data/PrimeKG_data/raw_data/drug_features.tab\"\n",
    "\n",
    "df = pd.read_csv(disease_tab, delimiter='\\t')\n",
    "disease_csv = \"~/scratch-llm/data/PrimeKG_data/sub_data/disease_features.csv\"\n",
    "df.to_csv(disease_csv, index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(drug_tab, delimiter='\\t')\n",
    "drug_csv = \"~/scratch-llm/data/PrimeKG_data/sub_data/drug_features.csv\"\n",
    "df.to_csv(drug_csv, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge extra drug and disease information \n",
    "node_drug = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/sub_data/node_drug.csv\")\n",
    "features_drug = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/sub_data/drug_features.csv\")\n",
    "node_disease = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/sub_data/node_disease.csv\")\n",
    "features_disease = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/sub_data/disease_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_disease = pd.read_csv(\"~/scratch-llm/data/PrimeKG_data/sub_data/node_disease.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_disease2 = pd.read_csv(\"~/scratch-llm/data/knowledge_graph/disease_features_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the disease_features has multiple rows with the same 'node_index' so we need to merge them\n",
    "def merge_column_values(column):\n",
    "    # Check if all values in the column can be converted to float\n",
    "    try:\n",
    "        numeric_column = pd.to_numeric(column, errors='coerce')\n",
    "        if numeric_column.notna().all():  # If all are numbers, return unique values\n",
    "            return '_'.join(map(str, sorted(set(numeric_column))))  # Keep the first numeric value (assuming they're the same)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # For strings, concatenate unique, non-empty values\n",
    "    return '; '.join(filter(lambda x: pd.notna(x) and str(x).strip() != '', set(column)))\n",
    "\n",
    "merged_features_disease = features_disease2.groupby('node_index', as_index=False).agg(merge_column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(node_disease, merged_features_disease, on='node_index')\n",
    "merged_df.to_csv(\"~/scratch-llm/data/node_merged_drug2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'node_index' and save to csv\n",
    "merged_df = pd.merge(node_drug, features_drug, on='node_index')\n",
    "merged_df.to_csv(\"~/scratch-llm/data/PrimeKG_data/sub_data/node_merged_drug.csv\", index=False)\n",
    "\n",
    "merged_df = pd.merge(node_disease, merged_features_disease, on='node_index')\n",
    "# merged_df.fillna(\"\", inplace=True) # in case included 'extra' diseases that are only present in features_disease\n",
    "merged_df.to_csv(\"~/scratch-llm/data/PrimeKG_data/sub_data/node_merged_disease.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the extended drug and disease data into the corresponding Tags\n",
    "# NOTE: formatting problems for node_merged_disease.csv\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_merged_disease.csv --tag disease --header --space PrimeKG --batch 50 --vid 0 --props 3:node_name,4:node_source,5:mondo_id,6:mondo_name,7:group_id_bert,8:group_name_bert,9:mondo_definition,10:umls_description,11:orphanet_definition,12:orphanet_prevalence,13:orphanet_epidemiology,14:orphanet_clinical_description,15:orphanet_management_and_treatment,16:mayo_symptoms,17:mayo_causes,18:mayo_risk_factors,19:mayo_complications,20:mayo_prevention,21:mayo_see_doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading diseases without extra info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;0;120;215m[INFO] Parsed 17080 vertices 'PrimeKG' for tag 'disease' in memory\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3c878ca8eb4954bda2ad610a6dc985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Vertices:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 of 17080 vertices\n",
      "Loaded 100 of 17080 vertices\n",
      "Loaded 150 of 17080 vertices\n",
      "Loaded 200 of 17080 vertices\n",
      "Loaded 250 of 17080 vertices\n",
      "Loaded 300 of 17080 vertices\n",
      "Loaded 350 of 17080 vertices\n",
      "Loaded 400 of 17080 vertices\n",
      "Loaded 450 of 17080 vertices\n",
      "Loaded 500 of 17080 vertices\n",
      "Loaded 550 of 17080 vertices\n",
      "Loaded 600 of 17080 vertices\n",
      "Loaded 650 of 17080 vertices\n",
      "Loaded 700 of 17080 vertices\n",
      "Loaded 750 of 17080 vertices\n",
      "Loaded 800 of 17080 vertices\n",
      "Loaded 850 of 17080 vertices\n",
      "Loaded 900 of 17080 vertices\n",
      "Loaded 950 of 17080 vertices\n",
      "Loaded 1000 of 17080 vertices\n",
      "Loaded 1050 of 17080 vertices\n",
      "Loaded 1100 of 17080 vertices\n",
      "Loaded 1150 of 17080 vertices\n",
      "Loaded 1200 of 17080 vertices\n",
      "Loaded 1250 of 17080 vertices\n",
      "Loaded 1300 of 17080 vertices\n",
      "Loaded 1350 of 17080 vertices\n",
      "Loaded 1400 of 17080 vertices\n",
      "Loaded 1450 of 17080 vertices\n",
      "Loaded 1500 of 17080 vertices\n",
      "Loaded 1550 of 17080 vertices\n",
      "Loaded 1600 of 17080 vertices\n",
      "Loaded 1650 of 17080 vertices\n",
      "Loaded 1700 of 17080 vertices\n",
      "Loaded 1750 of 17080 vertices\n",
      "Loaded 1800 of 17080 vertices\n",
      "Loaded 1850 of 17080 vertices\n",
      "Loaded 1900 of 17080 vertices\n",
      "Loaded 1950 of 17080 vertices\n",
      "Loaded 2000 of 17080 vertices\n",
      "Loaded 2050 of 17080 vertices\n",
      "Loaded 2100 of 17080 vertices\n",
      "Loaded 2150 of 17080 vertices\n",
      "Loaded 2200 of 17080 vertices\n",
      "Loaded 2250 of 17080 vertices\n",
      "Loaded 2300 of 17080 vertices\n",
      "Loaded 2350 of 17080 vertices\n",
      "Loaded 2400 of 17080 vertices\n",
      "Loaded 2450 of 17080 vertices\n",
      "Loaded 2500 of 17080 vertices\n",
      "Loaded 2550 of 17080 vertices\n",
      "Loaded 2600 of 17080 vertices\n",
      "Loaded 2650 of 17080 vertices\n",
      "Loaded 2700 of 17080 vertices\n",
      "Loaded 2750 of 17080 vertices\n",
      "Loaded 2800 of 17080 vertices\n",
      "Loaded 2850 of 17080 vertices\n",
      "Loaded 2900 of 17080 vertices\n",
      "Loaded 2950 of 17080 vertices\n",
      "Loaded 3000 of 17080 vertices\n",
      "Loaded 3050 of 17080 vertices\n",
      "Loaded 3100 of 17080 vertices\n",
      "Loaded 3150 of 17080 vertices\n",
      "Loaded 3200 of 17080 vertices\n",
      "Loaded 3250 of 17080 vertices\n",
      "Loaded 3300 of 17080 vertices\n",
      "Loaded 3350 of 17080 vertices\n",
      "Loaded 3400 of 17080 vertices\n",
      "Loaded 3450 of 17080 vertices\n",
      "Loaded 3500 of 17080 vertices\n",
      "Loaded 3550 of 17080 vertices\n",
      "Loaded 3600 of 17080 vertices\n",
      "Loaded 3650 of 17080 vertices\n",
      "Loaded 3700 of 17080 vertices\n",
      "Loaded 3750 of 17080 vertices\n",
      "Loaded 3800 of 17080 vertices\n",
      "Loaded 3850 of 17080 vertices\n",
      "Loaded 3900 of 17080 vertices\n",
      "Loaded 3950 of 17080 vertices\n",
      "Loaded 4000 of 17080 vertices\n",
      "Loaded 4050 of 17080 vertices\n",
      "Loaded 4100 of 17080 vertices\n",
      "Loaded 4150 of 17080 vertices\n",
      "Loaded 4200 of 17080 vertices\n",
      "Loaded 4250 of 17080 vertices\n",
      "Loaded 4300 of 17080 vertices\n",
      "Loaded 4350 of 17080 vertices\n",
      "Loaded 4400 of 17080 vertices\n",
      "Loaded 4450 of 17080 vertices\n",
      "Loaded 4500 of 17080 vertices\n",
      "Loaded 4550 of 17080 vertices\n",
      "Loaded 4600 of 17080 vertices\n",
      "Loaded 4650 of 17080 vertices\n",
      "Loaded 4700 of 17080 vertices\n",
      "Loaded 4750 of 17080 vertices\n",
      "Loaded 4800 of 17080 vertices\n",
      "Loaded 4850 of 17080 vertices\n",
      "Loaded 4900 of 17080 vertices\n",
      "Loaded 4950 of 17080 vertices\n",
      "Loaded 5000 of 17080 vertices\n",
      "Loaded 5050 of 17080 vertices\n",
      "Loaded 5100 of 17080 vertices\n",
      "Loaded 5150 of 17080 vertices\n",
      "Loaded 5200 of 17080 vertices\n",
      "Loaded 5250 of 17080 vertices\n",
      "Loaded 5300 of 17080 vertices\n",
      "Loaded 5350 of 17080 vertices\n",
      "Loaded 5400 of 17080 vertices\n",
      "Loaded 5450 of 17080 vertices\n",
      "Loaded 5500 of 17080 vertices\n",
      "Loaded 5550 of 17080 vertices\n",
      "Loaded 5600 of 17080 vertices\n",
      "Loaded 5650 of 17080 vertices\n",
      "Loaded 5700 of 17080 vertices\n",
      "Loaded 5750 of 17080 vertices\n",
      "Loaded 5800 of 17080 vertices\n",
      "Loaded 5850 of 17080 vertices\n",
      "Loaded 5900 of 17080 vertices\n",
      "Loaded 5950 of 17080 vertices\n",
      "Loaded 6000 of 17080 vertices\n",
      "Loaded 6050 of 17080 vertices\n",
      "Loaded 6100 of 17080 vertices\n",
      "Loaded 6150 of 17080 vertices\n",
      "Loaded 6200 of 17080 vertices\n",
      "Loaded 6250 of 17080 vertices\n",
      "Loaded 6300 of 17080 vertices\n",
      "Loaded 6350 of 17080 vertices\n",
      "Loaded 6400 of 17080 vertices\n",
      "Loaded 6450 of 17080 vertices\n",
      "Loaded 6500 of 17080 vertices\n",
      "Loaded 6550 of 17080 vertices\n",
      "Loaded 6600 of 17080 vertices\n",
      "Loaded 6650 of 17080 vertices\n",
      "Loaded 6700 of 17080 vertices\n",
      "Loaded 6750 of 17080 vertices\n",
      "Loaded 6800 of 17080 vertices\n",
      "Loaded 6850 of 17080 vertices\n",
      "Loaded 6900 of 17080 vertices\n",
      "Loaded 6950 of 17080 vertices\n",
      "Loaded 7000 of 17080 vertices\n",
      "Loaded 7050 of 17080 vertices\n",
      "Loaded 7100 of 17080 vertices\n",
      "Loaded 7150 of 17080 vertices\n",
      "Loaded 7200 of 17080 vertices\n",
      "Loaded 7250 of 17080 vertices\n",
      "Loaded 7300 of 17080 vertices\n",
      "Loaded 7350 of 17080 vertices\n",
      "Loaded 7400 of 17080 vertices\n",
      "Loaded 7450 of 17080 vertices\n",
      "Loaded 7500 of 17080 vertices\n",
      "Loaded 7550 of 17080 vertices\n",
      "Loaded 7600 of 17080 vertices\n",
      "Loaded 7650 of 17080 vertices\n",
      "Loaded 7700 of 17080 vertices\n",
      "Loaded 7750 of 17080 vertices\n",
      "Loaded 7800 of 17080 vertices\n",
      "Loaded 7850 of 17080 vertices\n",
      "Loaded 7900 of 17080 vertices\n",
      "Loaded 7950 of 17080 vertices\n",
      "Loaded 8000 of 17080 vertices\n",
      "Loaded 8050 of 17080 vertices\n",
      "Loaded 8100 of 17080 vertices\n",
      "Loaded 8150 of 17080 vertices\n",
      "Loaded 8200 of 17080 vertices\n",
      "Loaded 8250 of 17080 vertices\n",
      "Loaded 8300 of 17080 vertices\n",
      "Loaded 8350 of 17080 vertices\n",
      "Loaded 8400 of 17080 vertices\n",
      "Loaded 8450 of 17080 vertices\n",
      "Loaded 8500 of 17080 vertices\n",
      "Loaded 8550 of 17080 vertices\n",
      "Loaded 8600 of 17080 vertices\n",
      "Loaded 8650 of 17080 vertices\n",
      "Loaded 8700 of 17080 vertices\n",
      "Loaded 8750 of 17080 vertices\n",
      "Loaded 8800 of 17080 vertices\n",
      "Loaded 8850 of 17080 vertices\n",
      "Loaded 8900 of 17080 vertices\n",
      "Loaded 8950 of 17080 vertices\n",
      "Loaded 9000 of 17080 vertices\n",
      "Loaded 9050 of 17080 vertices\n",
      "Loaded 9100 of 17080 vertices\n",
      "Loaded 9150 of 17080 vertices\n",
      "Loaded 9200 of 17080 vertices\n",
      "Loaded 9250 of 17080 vertices\n",
      "Loaded 9300 of 17080 vertices\n",
      "Loaded 9350 of 17080 vertices\n",
      "Loaded 9400 of 17080 vertices\n",
      "Loaded 9450 of 17080 vertices\n",
      "Loaded 9500 of 17080 vertices\n",
      "Loaded 9550 of 17080 vertices\n",
      "Loaded 9600 of 17080 vertices\n",
      "Loaded 9650 of 17080 vertices\n",
      "Loaded 9700 of 17080 vertices\n",
      "Loaded 9750 of 17080 vertices\n",
      "Loaded 9800 of 17080 vertices\n",
      "Loaded 9850 of 17080 vertices\n",
      "Loaded 9900 of 17080 vertices\n",
      "Loaded 9950 of 17080 vertices\n",
      "Loaded 10000 of 17080 vertices\n",
      "Loaded 10050 of 17080 vertices\n",
      "Loaded 10100 of 17080 vertices\n",
      "Loaded 10150 of 17080 vertices\n",
      "Loaded 10200 of 17080 vertices\n",
      "Loaded 10250 of 17080 vertices\n",
      "Loaded 10300 of 17080 vertices\n",
      "Loaded 10350 of 17080 vertices\n",
      "Loaded 10400 of 17080 vertices\n",
      "Loaded 10450 of 17080 vertices\n",
      "Loaded 10500 of 17080 vertices\n",
      "Loaded 10550 of 17080 vertices\n",
      "Loaded 10600 of 17080 vertices\n",
      "Loaded 10650 of 17080 vertices\n",
      "Loaded 10700 of 17080 vertices\n",
      "Loaded 10750 of 17080 vertices\n",
      "Loaded 10800 of 17080 vertices\n",
      "Loaded 10850 of 17080 vertices\n",
      "Loaded 10900 of 17080 vertices\n",
      "Loaded 10950 of 17080 vertices\n",
      "Loaded 11000 of 17080 vertices\n",
      "Loaded 11050 of 17080 vertices\n",
      "Loaded 11100 of 17080 vertices\n",
      "Loaded 11150 of 17080 vertices\n",
      "Loaded 11200 of 17080 vertices\n",
      "Loaded 11250 of 17080 vertices\n",
      "Loaded 11300 of 17080 vertices\n",
      "Loaded 11350 of 17080 vertices\n",
      "Loaded 11400 of 17080 vertices\n",
      "Loaded 11450 of 17080 vertices\n",
      "Loaded 11500 of 17080 vertices\n",
      "Loaded 11550 of 17080 vertices\n",
      "Loaded 11600 of 17080 vertices\n",
      "Loaded 11650 of 17080 vertices\n",
      "Loaded 11700 of 17080 vertices\n",
      "Loaded 11750 of 17080 vertices\n",
      "Loaded 11800 of 17080 vertices\n",
      "Loaded 11850 of 17080 vertices\n",
      "Loaded 11900 of 17080 vertices\n",
      "Loaded 11950 of 17080 vertices\n",
      "Loaded 12000 of 17080 vertices\n",
      "Loaded 12050 of 17080 vertices\n",
      "Loaded 12100 of 17080 vertices\n",
      "Loaded 12150 of 17080 vertices\n",
      "Loaded 12200 of 17080 vertices\n",
      "Loaded 12250 of 17080 vertices\n",
      "Loaded 12300 of 17080 vertices\n",
      "Loaded 12350 of 17080 vertices\n",
      "Loaded 12400 of 17080 vertices\n",
      "Loaded 12450 of 17080 vertices\n",
      "Loaded 12500 of 17080 vertices\n",
      "Loaded 12550 of 17080 vertices\n",
      "Loaded 12600 of 17080 vertices\n",
      "Loaded 12650 of 17080 vertices\n",
      "Loaded 12700 of 17080 vertices\n",
      "Loaded 12750 of 17080 vertices\n",
      "Loaded 12800 of 17080 vertices\n",
      "Loaded 12850 of 17080 vertices\n",
      "Loaded 12900 of 17080 vertices\n",
      "Loaded 12950 of 17080 vertices\n",
      "Loaded 13000 of 17080 vertices\n",
      "Loaded 13050 of 17080 vertices\n",
      "Loaded 13100 of 17080 vertices\n",
      "Loaded 13150 of 17080 vertices\n",
      "Loaded 13200 of 17080 vertices\n",
      "Loaded 13250 of 17080 vertices\n",
      "Loaded 13300 of 17080 vertices\n",
      "Loaded 13350 of 17080 vertices\n",
      "Loaded 13400 of 17080 vertices\n",
      "Loaded 13450 of 17080 vertices\n",
      "Loaded 13500 of 17080 vertices\n",
      "Loaded 13550 of 17080 vertices\n",
      "Loaded 13600 of 17080 vertices\n",
      "Loaded 13650 of 17080 vertices\n",
      "Loaded 13700 of 17080 vertices\n",
      "Loaded 13750 of 17080 vertices\n",
      "Loaded 13800 of 17080 vertices\n",
      "Loaded 13850 of 17080 vertices\n",
      "Loaded 13900 of 17080 vertices\n",
      "Loaded 13950 of 17080 vertices\n",
      "Loaded 14000 of 17080 vertices\n",
      "Loaded 14050 of 17080 vertices\n",
      "Loaded 14100 of 17080 vertices\n",
      "Loaded 14150 of 17080 vertices\n",
      "Loaded 14200 of 17080 vertices\n",
      "Loaded 14250 of 17080 vertices\n",
      "Loaded 14300 of 17080 vertices\n",
      "Loaded 14350 of 17080 vertices\n",
      "Loaded 14400 of 17080 vertices\n",
      "Loaded 14450 of 17080 vertices\n",
      "Loaded 14500 of 17080 vertices\n",
      "Loaded 14550 of 17080 vertices\n",
      "Loaded 14600 of 17080 vertices\n",
      "Loaded 14650 of 17080 vertices\n",
      "Loaded 14700 of 17080 vertices\n",
      "Loaded 14750 of 17080 vertices\n",
      "Loaded 14800 of 17080 vertices\n",
      "Loaded 14850 of 17080 vertices\n",
      "Loaded 14900 of 17080 vertices\n",
      "Loaded 14950 of 17080 vertices\n",
      "Loaded 15000 of 17080 vertices\n",
      "Loaded 15050 of 17080 vertices\n",
      "Loaded 15100 of 17080 vertices\n",
      "Loaded 15150 of 17080 vertices\n",
      "Loaded 15200 of 17080 vertices\n",
      "Loaded 15250 of 17080 vertices\n",
      "Loaded 15300 of 17080 vertices\n",
      "Loaded 15350 of 17080 vertices\n",
      "Loaded 15400 of 17080 vertices\n",
      "Loaded 15450 of 17080 vertices\n",
      "Loaded 15500 of 17080 vertices\n",
      "Loaded 15550 of 17080 vertices\n",
      "Loaded 15600 of 17080 vertices\n",
      "Loaded 15650 of 17080 vertices\n",
      "Loaded 15700 of 17080 vertices\n",
      "Loaded 15750 of 17080 vertices\n",
      "Loaded 15800 of 17080 vertices\n",
      "Loaded 15850 of 17080 vertices\n",
      "Loaded 15900 of 17080 vertices\n",
      "Loaded 15950 of 17080 vertices\n",
      "Loaded 16000 of 17080 vertices\n",
      "Loaded 16050 of 17080 vertices\n",
      "Loaded 16100 of 17080 vertices\n",
      "Loaded 16150 of 17080 vertices\n",
      "Loaded 16200 of 17080 vertices\n",
      "Loaded 16250 of 17080 vertices\n",
      "Loaded 16300 of 17080 vertices\n",
      "Loaded 16350 of 17080 vertices\n",
      "Loaded 16400 of 17080 vertices\n",
      "Loaded 16450 of 17080 vertices\n",
      "Loaded 16500 of 17080 vertices\n",
      "Loaded 16550 of 17080 vertices\n",
      "Loaded 16600 of 17080 vertices\n",
      "Loaded 16650 of 17080 vertices\n",
      "Loaded 16700 of 17080 vertices\n",
      "Loaded 16750 of 17080 vertices\n",
      "Loaded 16800 of 17080 vertices\n",
      "Loaded 16850 of 17080 vertices\n",
      "Loaded 16900 of 17080 vertices\n",
      "Loaded 16950 of 17080 vertices\n",
      "Loaded 17000 of 17080 vertices\n",
      "Loaded 17050 of 17080 vertices\n",
      "Loaded 17080 of 17080 vertices\n",
      "\u001b[1;3;38;2;0;135;107m[INFO] Successfully loaded 17080 vertices 'PrimeKG' for tag 'disease'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_disease.csv --tag disease --header --space PrimeKG --batch 50 --vid 0 --props 3:node_name,4:node_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/node_merged_drug.csv --tag drug --header --space PrimeKG --batch 100 --vid 0 --props 2:node_id,3:node_name,4:node_source,5:description,6:half_life,7:indication,8:mechanism_of_action,9:protein_binding,10:pharmacodynamics,11:state,12:atc_1,13:atc_2,14:atc_3,15:atc_4,16:category,17:group,18:pathway,19:molecular_weight,20:tpsa,21:clogp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edges['relation'].unique()) # types of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data for each 'relation' (edge type) in a separate file\n",
    "for relation in edges['relation'].unique():\n",
    "    sanitized_relation = relation.replace('-', '_')\n",
    "    sanitized_relation = sanitized_relation.replace('\\t', '_')\n",
    "    output_path = os.path.join('~/scratch-llm/data/PrimeKG_data/sub_data/', 'edge_'+ sanitized_relation + '.csv')\n",
    "    edges[edges['relation'] == relation].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql CREATE EDGE IF NOT EXISTS protein_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS drug_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS contraindication(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS indication(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS off_label_use(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS drug_drug(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS phenotype_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS phenotype_phenotype(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS disease_phenotype_negative(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS disease_phenotype_positive(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS disease_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS disease_disease(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS drug_effect(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS bioprocess_bioprocess(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS molfunc_molfunc(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS cellcomp_cellcomp(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS molfunc_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS cellcomp_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS bioprocess_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS exposure_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS exposure_disease(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS exposure_exposure(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS exposure_bioprocess(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS exposure_molfunc(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS exposure_cellcomp(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS pathway_pathway(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS pathway_protein(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS anatomy_anatomy(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS anatomy_protein_present(display_relation string);\n",
    "%ngql CREATE EDGE IF NOT EXISTS anatomy_protein_absent(display_relation string);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each edge type, load the data accordingly, this takes like 20mins from new\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_protein_protein.csv --space PrimeKG --batch 100 --header --edge protein_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_drug_protein.csv --space PrimeKG --header --batch 100 --edge drug_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_contraindication.csv --space PrimeKG --header --batch 100 --edge contraindication --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_indication.csv --space PrimeKG --header --batch 100 --edge indication --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_off_label_use.csv --space PrimeKG --header --batch 100 --edge off_label_use --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_drug_drug.csv --space PrimeKG --header --batch 100 --edge drug_drug --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_phenotype_protein.csv --space PrimeKG --header --batch 100 --edge phenotype_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_phenotype_phenotype.csv --space PrimeKG --header --batch 100 --edge phenotype_phenotype --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_disease_phenotype_negative.csv --space PrimeKG --header --batch 100 --edge disease_phenotype_negative --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_disease_phenotype_positive.csv --space PrimeKG --header --batch 100 --edge disease_phenotype_positive --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_disease_protein.csv --space PrimeKG --header --batch 100 --edge disease_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_disease_disease.csv --space PrimeKG --header --batch 100 --edge disease_disease --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_drug_effect.csv --space PrimeKG --header --batch 100 --edge drug_effect --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_bioprocess_bioprocess.csv --space PrimeKG --header --batch 100 --edge bioprocess_bioprocess --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_molfunc_molfunc.csv --space PrimeKG --header --batch 100 --edge molfunc_molfunc --src 2 --dst 3 --props 1:display_relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the edge data in two batches\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_cellcomp_cellcomp.csv --space PrimeKG --header --batch 100 --edge cellcomp_cellcomp --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_molfunc_protein.csv --space PrimeKG --header --batch 100 --edge molfunc_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_cellcomp_protein.csv --space PrimeKG --header --batch 100 --edge cellcomp_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_bioprocess_protein.csv --space PrimeKG --header --batch 100 --edge bioprocess_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_exposure_protein.csv --space PrimeKG --header --batch 100 --edge exposure_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_exposure_disease.csv --space PrimeKG --header --batch 100 --edge exposure_disease --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_exposure_exposure.csv --space PrimeKG --header --batch 100 --edge exposure_exposure --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_exposure_bioprocess.csv --space PrimeKG --header --batch 100 --edge exposure_bioprocess --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_exposure_molfunc.csv --space PrimeKG --header --batch 100 --edge exposure_molfunc --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_exposure_cellcomp.csv --space PrimeKG --header --batch 100 --edge exposure_cellcomp --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_pathway_pathway.csv --space PrimeKG --header --batch 100 --edge pathway_pathway --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_pathway_protein.csv --space PrimeKG --header --batch 100 --edge pathway_protein --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_anatomy_anatomy.csv --space PrimeKG --header --batch 100 --edge anatomy_anatomy --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_anatomy_protein_present.csv --space PrimeKG --batch 100 --header --edge anatomy_protein_present --src 2 --dst 3 --props 1:display_relation\n",
    "%ng_load --source ~/scratch-llm/data/PrimeKG_data/sub_data/edge_anatomy_protein_absent.csv --space PrimeKG --header --batch 100 --edge anatomy_protein_absent --src 2 --dst 3 --props 1:display_relation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load directly to NebulaPropertyGraphStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define files to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '~/scratch-llm/data/PrimeKG_data/sub_data/'\n",
    "\n",
    "# List of node types and their corresponding CSV files\n",
    "node_files = {\n",
    "    'node_gene_protein.csv',\n",
    "    'node_merged_drug.csv', # manually corrected and generated from \"extra information section\"\n",
    "    'node_effect_phenotype.csv',\n",
    "    'node_merged_disease.csv', # manually corrected and generated from \"extra information section\"\n",
    "    'node_biological_process.csv',\n",
    "    'node_molecular_function.csv',\n",
    "    'node_cellular_component.csv',\n",
    "    'node_exposure.csv',\n",
    "    'node_pathway.csv',\n",
    "    'node_anatomy.csv'\n",
    "}\n",
    "\n",
    "edge_files ={\n",
    "    'edge_protein_protein.csv',\n",
    "    'edge_drug_protein.csv',\n",
    "    'edge_contraindication.csv',\n",
    "    'edge_indication.csv',\n",
    "    'edge_off_label_use.csv',\n",
    "    'edge_drug_drug.csv',\n",
    "    'edge_phenotype_protein.csv',\n",
    "    'edge_phenotype_phenotype.csv',\n",
    "    'edge_disease_phenotype_negative.csv',\n",
    "    'edge_disease_phenotype_positive.csv',\n",
    "    'edge_disease_protein.csv',\n",
    "    'edge_disease_disease.csv',\n",
    "    'edge_drug_effect.csv',\n",
    "    'edge_bioprocess_bioprocess.csv',\n",
    "    'edge_molfunc_molfunc.csv',\n",
    "    'edge_cellcomp_cellcomp.csv',\n",
    "    'edge_molfunc_protein.csv',\n",
    "    'edge_cellcomp_protein.csv',\n",
    "    'edge_bioprocess_protein.csv',\n",
    "    'edge_exposure_protein.csv',\n",
    "    'edge_exposure_disease.csv',\n",
    "    'edge_exposure_exposure.csv',\n",
    "    'edge_exposure_bioprocess.csv',\n",
    "    'edge_exposure_molfunc.csv',\n",
    "    'edge_exposure_cellcomp.csv',\n",
    "    'edge_pathway_pathway.csv',\n",
    "    'edge_pathway_protein.csv',\n",
    "    'edge_anatomy_anatomy.csv',\n",
    "    'edge_anatomy_protein_present.csv',\n",
    "    'edge_anatomy_protein_absent.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create TextNodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TextNodes\n",
    "def create_text_nodes(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    text_nodes = []\n",
    "    for _, row in df.iterrows():\n",
    "        id = row['node_index']\n",
    "        if len(row) > 5: # longer text info (drug/disease)\n",
    "            metadata_columns = ['node_index', 'node_id', 'node_type', 'node_name', \n",
    "                            'node_source', 'mondo_id', 'mondo_name', 'group_id_bert', \n",
    "                            'group_name_bert', 'orphanet_prevalence']\n",
    "            \n",
    "            text_columns = ['mondo_definition', 'umls_description', 'orphanet_definition', \n",
    "                        'orphanet_clinical_description', 'orphanet_management_and_treatment','orphanet_epidemiology', \n",
    "                        'mayo_symptoms', 'mayo_causes', 'mayo_risk_factors', 'mayo_complications',\n",
    "                        'mayo_prevention', 'mayo_see_doc','description', 'indication', 'mechanism_of_action',\n",
    "                        'half_life', 'protein_binding', 'pharmacodynamics', 'state', 'atc_1', 'atc_2', 'atc_3', \n",
    "                        'atc_4', 'category', 'group', 'pathway', 'molecular_weight', 'tpsa', 'clogp'] \n",
    "            available_metadata_columns = [col for col in metadata_columns if col in df.columns]\n",
    "            available_text_columns = [col for col in text_columns if col in df.columns] \n",
    "\n",
    "            # Extract metadata, not including empty entries     \n",
    "            metadata = {\n",
    "                col: row[col] for col in available_metadata_columns\n",
    "                if col in row and not (isinstance(row[col], float) and math.isnan(row[col]))\n",
    "            }\n",
    "            metadata = {k: str(v) for k, v in metadata.items()} #ensure entries are strings\n",
    "\n",
    "            # Extract and concatenate text values, not including empty entries\n",
    "            text_entries = [str(row[col]) for col in available_text_columns if pd.notna(row[col])]\n",
    "            text = \"\\n\".join(text_entries)            \n",
    "\n",
    "            text_node = TextNode(id_= str(id), text=text, metadata=metadata)\n",
    "            text_nodes.append(text_node)\n",
    "\n",
    "        else: # no text data, all other files\n",
    "            metadata = row.to_dict()\n",
    "            metadata = {k: str(v) for k, v in metadata.items()} #ensure entries are strings\n",
    "            text_node = TextNode(id_= str(id), metadata=metadata)\n",
    "            text_nodes.append(text_node)\n",
    "\n",
    "    return text_nodes\n",
    "\n",
    "# generate all nodes from the node files\n",
    "all_nodes = []\n",
    "for file in node_files:\n",
    "    nodes = create_text_nodes(data_dir+file)\n",
    "    all_nodes.extend(nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Entity and ChunkNodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TextNode objects to the format expected by NebulaPropertyGraphStore\n",
    "from llama_index.core.graph_stores.types import EntityNode, ChunkNode\n",
    "all_entity_nodes = []\n",
    "\n",
    "def create_entity_nodes(file_path, label):\n",
    "    df = pd.read_csv(file_path)\n",
    "    nodes = []\n",
    "    for _, row in df.iterrows():\n",
    "        text=None\n",
    "        id = row['node_index']\n",
    "        metadata_columns = ['node_index', 'node_id', 'node_type', 'node_name', \n",
    "                            'node_source', 'mondo_id', 'mondo_name', 'group_id_bert', \n",
    "                            'group_name_bert', 'orphanet_prevalence']\n",
    "        \n",
    "        text_columns = ['mondo_definition', 'umls_description', 'orphanet_definition', \n",
    "                        'orphanet_clinical_description', 'orphanet_management_and_treatment','orphanet_epidemiology', \n",
    "                        'mayo_symptoms', 'mayo_causes', 'mayo_risk_factors', 'mayo_complications',\n",
    "                        'mayo_prevention', 'mayo_see_doc','description', 'indication', 'mechanism_of_action',\n",
    "                        'half_life', 'protein_binding', 'pharmacodynamics', 'state', 'atc_1', 'atc_2', 'atc_3', \n",
    "                        'atc_4', 'category', 'group', 'pathway', 'molecular_weight', 'tpsa', 'clogp'] \n",
    "        available_metadata_columns = [col for col in metadata_columns if col in df.columns]\n",
    "        available_text_columns = [col for col in text_columns if col in df.columns] \n",
    "\n",
    "        # Extract metadata, not including empty entries     \n",
    "        metadata = {\n",
    "            col: row[col] for col in available_metadata_columns\n",
    "            if col in row and not (isinstance(row[col], float) and math.isnan(row[col]))\n",
    "        }\n",
    "        metadata = {k: str(v) for k, v in metadata.items()}  # ensure entries are strings\n",
    "\n",
    "        # Extract and concatenate text values, not including empty entries\n",
    "        text_entries = [str(row[col]) for col in available_text_columns if pd.notna(row[col])]\n",
    "        text = \" \".join(text_entries)            \n",
    "\n",
    "        if text is not None:  # if there is text data, create a ChunkNode\n",
    "            node = ChunkNode(id_=str(id), label=label, properties=metadata, text=text)\n",
    "        else:  # if there is no text data, empty ChunkNode\n",
    "            node = ChunkNode(id_=str(id), label=label, properties=metadata, text='')\n",
    "        \n",
    "        nodes.append(node)\n",
    "\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in node_files:\n",
    "    # remove 'node_' and '.csv' and merged_ from the label\n",
    "    label = file.replace('node_', '').replace('.csv', '').replace('merged_', '')\n",
    "    nodes = create_entity_nodes(data_dir + file, label)\n",
    "    all_entity_nodes.extend(nodes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pickle\n",
    "with open(os.path.expanduser('~/scratch-llm/storage/all_entity_nodes.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_entity_nodes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append edges to TextNodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all edges\n",
    "\n",
    "def create_all_edges(file_path, all_nodes):\n",
    "    node_dict = {node.id_: node for node in all_nodes} #speed up search\n",
    "    df = pd.read_csv(os.path.join(file_path))\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), leave=False, desc=f\"Processing {file_path}\"):\n",
    "        x_index = str(row['x_index'])\n",
    "        y_index = str(row['y_index'])\n",
    "        \n",
    "        if x_index in node_dict:\n",
    "            origin_node = node_dict[x_index]\n",
    "            if NodeRelationship.CHILD not in origin_node.relationships:\n",
    "                origin_node.relationships[NodeRelationship.CHILD] = []\n",
    "           \n",
    "            metadata = row.drop(['x_index', 'y_index']).to_dict()\n",
    "            new_relationship = RelatedNodeInfo(node_id=y_index, metadata=metadata)\n",
    "            origin_node.relationships[NodeRelationship.CHILD].append(new_relationship)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all relationships for all nodes, takes around 20 mins\n",
    "for file in tqdm(edge_files, desc='Procesing edge files'):\n",
    "    create_all_edges(data_dir+file, all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save nodes-relationships to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save `all_nodes` with pickle\n",
    "with open(os.path.expanduser('~/scratch-llm/storage/all_nodes.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_nodes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Relations for Entity/ChunkNodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.graph_stores.types import Relation\n",
    "\n",
    "def create_realtions(file_path, label):\n",
    "    df = pd.read_csv(file_path)\n",
    "    relations = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), leave=False, desc=f\"Processing {file_path}\"):\n",
    "        start_node = row['x_index']\n",
    "        end_node = row['y_index']\n",
    "        properties = row.drop(['relation']).to_dict()\n",
    "        properties = row.drop(['relation', 'x_index', 'y_index']).to_dict()\n",
    "        relation = Relation(source_id=str(start_node), target_id=str(end_node), label=label, properties=properties)\n",
    "        relations.append(relation)\n",
    "    return relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations = [] \n",
    "for file in tqdm(edge_files, desc='Procesing edge files'): #35 mins\n",
    "    relations = create_realtions(data_dir+file, file[5:-4].replace('_', '-'))\n",
    "    all_relations.extend(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save relations with pickle\n",
    "with open(os.path.expanduser('~/scratch-llm/storage/all_relations.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_relations, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate node embeddings manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\"BAAI/bge-small-en-v1.5\",\n",
    "                \"all-mpnet-base-v2\",\n",
    "                \"BAAI/bge-m3\",\n",
    "                \"all-MiniLM-L6-v2\",  \n",
    "                \"all-MiniLM-L12-v2\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings for TextNodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_nodes(nodes: Sequence[BaseNode], embed_model=None, use_async=True, show_progress=False) -> Sequence[BaseNode]:\n",
    "    \"\"\"Embed nodes with specified embedding model.\"\"\"\n",
    "    if embed_model is None:\n",
    "        embed_model = Settings.embed_model  # Use default embed model from settings\n",
    "\n",
    "    embed_model = resolve_embed_model(embed_model)\n",
    "\n",
    "    node_texts = []\n",
    "    for node in nodes:\n",
    "        node_text = node.metadata[\"node_name\"]        \n",
    "        \n",
    "        # Add text content if it exists\n",
    "        content = node.get_content(metadata_mode=MetadataMode.NONE)\n",
    "        if content and content.strip():\n",
    "            cleaned_content = re.sub(r'\\n+', ' ', content)\n",
    "            node_text += f\": {cleaned_content}\"\n",
    "        \n",
    "        node_texts.append(node_text)\n",
    "    print(f\"Embedding {len(node_texts)} nodes\")\n",
    "\n",
    "    if use_async:\n",
    "        embeddings = embed_model.aget_text_embedding_batch(node_texts, show_progress=show_progress)\n",
    "    else:\n",
    "        embeddings = embed_model.get_text_embedding_batch(node_texts, show_progress=show_progress)\n",
    "\n",
    "    for node, embedding in zip(nodes, embeddings):\n",
    "        node.embedding = embedding\n",
    "\n",
    "    return nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all_nodes from pickle\n",
    "with open(os.path.expanduser('~/scratch-llm/storage/nodes/all_nodes.pkl'), 'rb') as f:\n",
    "    all_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in model_names:\n",
    "    print(f\"Embedding nodes with model: {name}\")\n",
    "    Settings.embed_model = HuggingFaceEmbedding(model_name=name)\n",
    "    all_nodes_embedded = embed_nodes(all_nodes, embed_model=Settings.embed_model, use_async=False, show_progress=True)\n",
    "    with open(os.path.expanduser(f'~/scratch-llm/storage/nodes/all_nodes_{name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_nodes_embedded, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph store: upsert nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and NebulaPropertyGraphStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.expanduser('~/scratch-llm/storage/nodes/all_entity_nodes.pkl'), 'rb') as f:\n",
    "    all_entity_nodes = pickle.load(f)\n",
    "\n",
    "#load relations with pickle\n",
    "with open(os.path.expanduser('~/scratch-llm/storage/all_relations.pkl'), 'rb') as f:\n",
    "    all_relations = pickle.load(f)\n",
    "\n",
    "# PropertyGraphIndex requires NebulaPropertyGraphStore\n",
    "graph_store = NebulaPropertyGraphStore(\n",
    "    space= \"PrimeKG\", \n",
    "    username = \"root\",\n",
    "    password = \"nebula\",\n",
    "    url = \"nebula://localhost:9669\",\n",
    "    props_schema= \"`node_index` STRING, `node_type` STRING, `node_id` STRING, `node_name` STRING, `node_source` STRING, `mondo_id` STRING, `mondo_name` STRING, `group_id_bert` STRING, `group_name_bert` STRING, `orphanet_prevalence` STRING, `umls_description` STRING, `orphanet_definition` STRING, `orphanet_epidemiology` STRING, `orphanet_clinical_description` STRING, `orphanet_management_and_treatment` STRING, `mayo_symptoms` STRING, `mayo_causes` STRING, `mayo_risk_factors` STRING, `mayo_complications` STRING, `mayo_prevention` STRING, `mayo_see_doc` STRING, `display_relation` STRING, `_node_content` STRING, `_node_type` STRING, `document_id` STRING, `doc_id` STRING, `ref_doc_id` STRING, `triplet_source_id` STRING\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upsert Entity/ChunkNodes (nodes) and Relations (edges) into the NebulaPropertyGraphStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all node_id values are strings\n",
    "for node in all_entity_nodes:\n",
    "    node.properties['node_id'] = str(node.properties['node_id'])\n",
    "\n",
    "# Upsert all nodes to the graph store in batches of 1000, there is no batch_size parameter, 4 mins\n",
    "for i in tqdm(range(0, len(all_entity_nodes), 1000), desc='Upserting nodes'):\n",
    "    batch = all_entity_nodes[i:i+1000]\n",
    "    graph_store.upsert_nodes(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsert edges for all nodes, 70 mins\n",
    "for i in tqdm(range(0, len(all_relations), 1000), desc='Upserting edges'):\n",
    "    batch = all_relations[i:i+1000]\n",
    "    graph_store.upsert_relations(batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
